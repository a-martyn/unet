{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from utils import *\n",
    "from model.data_loader import *\n",
    "from model.data_loader_old import *\n",
    "from model.unet_baseline import unet\n",
    "from model.unet_ternaus import ternausNet16\n",
    "from model.unet_ternaus_tweaked import ternausNet16_tweaked\n",
    "from model.unet_pix2pix_paper import unet_pix2pix_paper\n",
    "from model.unet_pix2pix_pytorch import unet_pix2pix_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pth = 'data/membrane/train'\n",
    "test_pth = 'data/membrane/test'\n",
    "results_pth = 'results/'\n",
    "pretrained_pth = 'pretrained/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_generator_train = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    rescale=1./255,           #  rescale pixel vals 0-255 --> 0.0-1.0\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect', #nearest\n",
    "    data_format='channels_last',\n",
    "    validation_split=0.0\n",
    ")\n",
    "target_generator_train = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    # No brightness transform on target mask\n",
    "    rescale=1./255,           #  rescale pixel vals 0-255 --> 0.0-1.0\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect',\n",
    "    data_format='channels_last',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "input_generator_test = ImageDataGenerator(\n",
    "    rescale=1./255,           #  rescale pixel vals 0-255 --> 0.0-1.0\n",
    "    fill_mode='reflect',\n",
    "    data_format='channels_last',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "target_generator_test = ImageDataGenerator(\n",
    "    rescale=1./255,           #  rescale pixel vals 0-255 --> 0.0-1.0\n",
    "    fill_mode='reflect',\n",
    "    data_format='channels_last',\n",
    "    validation_split=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models under test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sz = (512, 512, 1)\n",
    "batch_sz = 2\n",
    "\n",
    "# Models\n",
    "models = [\n",
    "    ['unet_baseline', unet, dict(input_size=img_sz, transpose=True)]\n",
    "]\n",
    "\n",
    "# Data loaders\n",
    "train_loader = loader(train_pth, input_generator_train, target_generator_train, batch_sz=batch_sz, img_sz=img_sz[:2])\n",
    "test_loader = loader(test_pth, input_generator_test, target_generator_test, batch_sz=batch_sz, img_sz=img_sz[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_title = 'baseline_512px_500steps_10epochs'\n",
    "\n",
    "training_params = dict(\n",
    "    train_steps=500, \n",
    "    val_steps=100, \n",
    "    epochs=10, \n",
    "    iterations=1, \n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "for model in models:\n",
    "    print(f'\\nTESTING MODEL: {model[0]}')\n",
    "    save_pth = f'{pretrained_pth}{model[0]}_{test_title}.h5'\n",
    "    results = test_model(model[1], train_loader, test_loader, **training_params, \n",
    "                         model_params=model[2], save_pth=save_pth)\n",
    "    results_df = hists2df(results)\n",
    "    results_df.to_csv(f'{results_pth}{model[0]}_{test_title}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Test: 5 epochs of 2000 training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sz = (256, 256, 1)\n",
    "batch_sz = 2\n",
    "\n",
    "# Models\n",
    "models = [\n",
    "    ['unet_baseline',           unet,                 dict(input_size=img_sz, transpose=True)],\n",
    "    ['unet_baseline_upsampled', unet,                 dict(input_size=img_sz, transpose=False)],\n",
    "    ['unet_pix2pix_paper',      unet_pix2pix_paper,   dict(input_size=img_sz)],\n",
    "    ['unet_pix2pix_pytorch',    unet_pix2pix_pytorch, dict(input_size=img_sz)],\n",
    "    ['unet_ternaus_nopre',      ternausNet16_tweaked, dict(input_size=img_sz, dropout=False, batch_norm=False, pretrained=False)],\n",
    "    ['unet_ternaus',            ternausNet16,         dict(input_size=img_sz)],\n",
    "    ['unet_ternaus_drop',       ternausNet16_tweaked, dict(input_size=img_sz, dropout=True,  batch_norm=False, pretrained=True)],\n",
    "    ['unet_ternaus_bn',         ternausNet16_tweaked, dict(input_size=img_sz, dropout=False, batch_norm=True,  pretrained=True)],\n",
    "    ['unet_ternaus_dropbn',     ternausNet16_tweaked, dict(input_size=img_sz, dropout=True,  batch_norm=True,  pretrained=True)]\n",
    "]\n",
    "\n",
    "# Data loaders\n",
    "train_loader = loader(train_pth, input_generator_train, target_generator_train, batch_sz=batch_sz, img_sz=img_sz[:2])\n",
    "test_loader = loader(test_pth, input_generator_test, target_generator_test, batch_sz=batch_sz, img_sz=img_sz[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING MODEL: unet_baseline\n",
      "Epoch 1/5\n",
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 1.1967 - acc: 0.9010Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "2000/2000 [==============================] - 992s 496ms/step - loss: 1.1966 - acc: 0.9010 - val_loss: 1.0991 - val_acc: 0.9367\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 985s 493ms/step - loss: 1.0032 - acc: 0.9439 - val_loss: 1.0317 - val_acc: 0.9312\n",
      "Epoch 3/5\n",
      "  48/2000 [..............................] - ETA: 15:29 - loss: 0.9253 - acc: 0.9513"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6aafd7c37f86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msave_pth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{pretrained_pth}{model[0]}.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     results = test_model(model[1], train_loader, test_loader, **training_params, \n\u001b[0;32m---> 15\u001b[0;31m                          model_params=model[2], save_pth=save_pth)\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhists2df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{results_pth}{model[0]}_{test_title}.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/unet/utils.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model_fn, train_loader, test_loader, train_steps, val_steps, epochs, iterations, lr, model_params, save_pth)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         history = model.fit_generator(train_loader, steps_per_epoch=train_steps, epochs=epochs,\n\u001b[0;32m---> 20\u001b[0;31m                                       validation_data=test_loader, validation_steps=val_steps)\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mhists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Save trained model weights if pth given and last iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 176\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_title = '5epochs'\n",
    "\n",
    "training_params = dict(\n",
    "    train_steps=500, \n",
    "    val_steps=100, \n",
    "    epochs=5, \n",
    "    iterations=3, \n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "for model in models:\n",
    "    print(f'\\nTESTING MODEL: {model[0]}')\n",
    "    save_pth = f'{pretrained_pth}{model[0]}.h5'\n",
    "    results = test_model(model[1], train_loader, test_loader, **training_params, \n",
    "                         model_params=model[2], save_pth=save_pth)\n",
    "    results_df = hists2df(results)\n",
    "    results_df.to_csv(f'{results_pth}{model[0]}_{test_title}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING MODEL: unet_baseline \n",
    "train_steps=1000\n",
    "epochs=5\n",
    "\n",
    "new augmentation\n",
    "\n",
    "loss: 0.4721 - acc: 0.8949 - val_loss: 0.3291 - val_acc: 0.9325\n",
    "loss: 0.3288 - acc: 0.9284 - val_loss: 0.3316 - val_acc: 0.9346\n",
    "loss: 0.2828 - acc: 0.9381 - val_loss: 0.3206 - val_acc: 0.9349\n",
    "loss: 0.2543 - acc: 0.9443 - val_loss: 0.3570 - val_acc: 0.9299  <--overfitting\n",
    "loss: 0.2304 - acc: 0.9496 - val_loss: 0.3599 - val_acc: 0.9341\n",
    "\n",
    "512px\n",
    "loss: 1.1966 - acc: 0.9010 - val_loss: 1.0991 - val_acc: 0.9367\n",
    "loss: 1.0032 - acc: 0.9439 - val_loss: 1.0317 - val_acc: 0.9312  <--overfitting\n",
    "\n",
    "old augmentation\n",
    "\n",
    ",val_loss,val_acc,loss,acc,experiment,epoch\n",
    "0,0.3938294525444508,0.9204465866088867,0.5577377219498157,0.8792923736572266,0.0,0.0\n",
    "1,0.3559911660850048,0.9349861907958984,0.4401548975408077,0.9053520278930665,0.0,1.0\n",
    "2,0.39109488159418104,0.9267212295532227,0.4238285449743271,0.9082808227539062,0.0,2.0    <--overfitting\n",
    "3,0.4155013260245323,0.9168938446044922,0.42954228895902635,0.9082791290283203,0.0,3.0\n",
    "4,0.36537827536463735,0.9267246627807617,0.39881821677088736,0.9130117721557617,0.0,4.0\n",
    "\n",
    "5,0.49226998195052146,0.9182594680786133,0.6562534253895282,0.8670453491210938,1.0,0.0\n",
    "6,0.4583278933167458,0.9273256683349609,0.554767794162035,0.8987517471313476,1.0,1.0\n",
    "7,0.4612529504299164,0.9287994384765625,0.5254129691720009,0.904376106262207,1.0,2.0\n",
    "8,0.4672836236655712,0.9274766540527344,0.5032809109687805,0.9079330139160157,1.0,3.0   <--overfitting\n",
    "9,0.4568671178817749,0.922571907043457,0.5079058838784695,0.9074051818847656,1.0,4.0\n",
    "\n",
    "10,1.3314954286813736,0.7966962432861329,1.3639041519165038,0.7678601226806641,2.0,0.0\n",
    "11,1.282408196926117,0.7967258834838867,1.3139923479557036,0.7705478591918945,2.0,1.0\n",
    "12,1.2392406225204469,0.7965563201904297,1.273618043422699,0.7686567840576172,2.0,2.0\n",
    "13,1.2005380243062973,0.7966357803344727,1.237180896639824,0.769509765625,2.0,3.0\n",
    "14,1.166281766295433,0.7965296936035157,1.2050516810417176,0.7705629653930665,2.0,4.0\n",
    "\n",
    "15,0.47512905225157737,0.9222694778442383,0.6407421391904354,0.8729847259521485,3.0,0.0\n",
    "16,0.4551257087290287,0.9326386260986328,0.5516852941811085,0.8992034530639649,3.0,1.0\n",
    "17,0.47955494463443754,0.9300589370727539,0.5159895688593388,0.9065925064086914,3.0,2.0 \n",
    "18,0.4419742250442505,0.9331255340576172,0.5083408271372318,0.9076029663085937,3.0,3.0\n",
    "19,0.4340150611102581,0.9320641326904296,0.4795567348897457,0.9116422729492187,3.0,4.0    <--overfitting\n",
    "\n",
    "20,0.37043760359287264,0.9277394485473632,0.5708116674721241,0.8749972534179687,4.0,0.0\n",
    "21,0.3530151304602623,0.9324607086181641,0.4412955792546272,0.9052258071899414,4.0,1.0\n",
    "22,0.3365512517094612,0.935040283203125,0.43223093220591546,0.9074309005737304,4.0,2.0\n",
    "23,0.3444555760920048,0.930106315612793,0.4199221305847168,0.9092439498901367,4.0,3.0   <--overfitting\n",
    "24,0.34377639517188074,0.9305371475219727,0.40034309843182564,0.9129037475585937,4.0,4.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TESTING MODEL: unet_ternaus\n",
    "train_steps=2000\n",
    "epochs=5\n",
    "\n",
    "loss: 0.3033 - acc: 0.9342 - val_loss: 0.3997 - val_acc: 0.9302\n",
    "loss: 0.1896 - acc: 0.9586 - val_loss: 0.4191 - val_acc: 0.9312\n",
    "loss: 0.1561 - acc: 0.9660 - val_loss: 0.4229 - val_acc: 0.9336\n",
    "loss: 0.1372 - acc: 0.9701 - val_loss: 0.4552 - val_acc: 0.9294  <--overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast test: 50 training steps\n",
    "\n",
    "## Compare baseline implementation to more recent u-net implementations\n",
    "\n",
    "\n",
    "TODO: update\n",
    "\n",
    "It is observed that the final accuracy of both models varies in the range 80-96% when trained for 5 epochs with 2000 iterations. How can we quickly compare the performance of these two models?\n",
    "\n",
    "Here's a quick comparison of models by training each for 50 training steps from scratch 30 times. We compare our baseline implementation to [zhixuhao's model](https://github.com/zhixuhao/unet) and find no significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING MODEL: unet_ternaus_nopre\n",
      "LAYER:: input_3\n",
      "LAYER:: conv2d_13\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d_5\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_6\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_7\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_8\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_9\n",
      "LAYER:: up_sampling2d_5\n",
      "LAYER:: conv2d_14\n",
      "LAYER:: batch_normalization_2\n",
      "LAYER:: conv2d_15\n",
      "LAYER:: batch_normalization_3\n",
      "LAYER:: concatenate_5\n",
      "LAYER:: up_sampling2d_6\n",
      "LAYER:: conv2d_16\n",
      "LAYER:: conv2d_17\n",
      "LAYER:: concatenate_6\n",
      "LAYER:: up_sampling2d_7\n",
      "LAYER:: conv2d_18\n",
      "LAYER:: conv2d_19\n",
      "LAYER:: concatenate_7\n",
      "LAYER:: up_sampling2d_8\n",
      "LAYER:: conv2d_20\n",
      "LAYER:: conv2d_21\n",
      "LAYER:: concatenate_8\n",
      "LAYER:: up_sampling2d_9\n",
      "LAYER:: conv2d_22\n",
      "LAYER:: conv2d_23\n",
      "LAYER:: concatenate_9\n",
      "LAYER:: conv2d_24\n",
      "LAYER:: re_lu_1\n",
      "LAYER:: conv2d_25\n",
      "LAYER:: activation_1\n",
      "Epoch 1/1\n",
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "49/50 [============================>.] - ETA: 0s - loss: 1.0852 - acc: 0.7519Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 1.0836 - acc: 0.7520 - val_loss: 0.9726 - val_acc: 0.7968\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 1.0501 - acc: 0.7649 - val_loss: 0.8926 - val_acc: 0.7967\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 27s 532ms/step - loss: 1.0622 - acc: 0.7728 - val_loss: 0.9463 - val_acc: 0.7967\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 1.0295 - acc: 0.7731 - val_loss: 0.8627 - val_acc: 0.7967\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 517ms/step - loss: 1.0496 - acc: 0.7595 - val_loss: 0.9026 - val_acc: 0.7969\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 522ms/step - loss: 1.0237 - acc: 0.7573 - val_loss: 0.8846 - val_acc: 0.7979\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 27s 530ms/step - loss: 1.0661 - acc: 0.7569 - val_loss: 0.9034 - val_acc: 0.7968\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 1.0601 - acc: 0.7656 - val_loss: 0.8955 - val_acc: 0.7968\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 1.0628 - acc: 0.7591 - val_loss: 0.9180 - val_acc: 0.7967\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 27s 532ms/step - loss: 1.0343 - acc: 0.7647 - val_loss: 0.8871 - val_acc: 0.7968\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 1.0243 - acc: 0.7666 - val_loss: 0.8571 - val_acc: 0.7967\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 521ms/step - loss: 1.0088 - acc: 0.7684 - val_loss: 0.8545 - val_acc: 0.8062\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 1.0799 - acc: 0.7633 - val_loss: 0.9440 - val_acc: 0.7966\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 521ms/step - loss: 1.0283 - acc: 0.7705 - val_loss: 0.8670 - val_acc: 0.7966\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 1.0817 - acc: 0.7506 - val_loss: 0.9308 - val_acc: 0.7965\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 1.0439 - acc: 0.7688 - val_loss: 0.8831 - val_acc: 0.7968\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 511ms/step - loss: 1.0486 - acc: 0.7576 - val_loss: 0.8724 - val_acc: 0.7967\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 1.0249 - acc: 0.7698 - val_loss: 0.8759 - val_acc: 0.7966\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 1.0626 - acc: 0.7582 - val_loss: 0.9017 - val_acc: 0.7967\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 521ms/step - loss: 1.0538 - acc: 0.7516 - val_loss: 0.9075 - val_acc: 0.7968\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 1.0187 - acc: 0.7702 - val_loss: 0.8555 - val_acc: 0.7966\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 1.0637 - acc: 0.7571 - val_loss: 0.9121 - val_acc: 0.7968\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 521ms/step - loss: 1.0095 - acc: 0.7622 - val_loss: 0.9270 - val_acc: 0.8026\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 1.0323 - acc: 0.7614 - val_loss: 0.8617 - val_acc: 0.7981\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 1.0413 - acc: 0.7621 - val_loss: 0.9571 - val_acc: 0.7968\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 1.0455 - acc: 0.7611 - val_loss: 1.0269 - val_acc: 0.8012\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 1.0765 - acc: 0.7601 - val_loss: 0.9589 - val_acc: 0.7967\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 1.0985 - acc: 0.7501 - val_loss: 0.9803 - val_acc: 0.7965\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 1.0453 - acc: 0.7562 - val_loss: 0.9226 - val_acc: 0.7979\n",
      "LAYER:: input_1\n",
      "LAYER:: conv2d\n",
      "LAYER:: block1_conv1\n",
      "reinitializing layer block1_conv1.kernel\n",
      "reinitializing layer block1_conv1.bias\n",
      "LAYER:: block1_conv2\n",
      "reinitializing layer block1_conv2.kernel\n",
      "reinitializing layer block1_conv2.bias\n",
      "LAYER:: max_pooling2d\n",
      "LAYER:: block2_conv1\n",
      "reinitializing layer block2_conv1.kernel\n",
      "reinitializing layer block2_conv1.bias\n",
      "LAYER:: block2_conv2\n",
      "reinitializing layer block2_conv2.kernel\n",
      "reinitializing layer block2_conv2.bias\n",
      "LAYER:: max_pooling2d_1\n",
      "LAYER:: block3_conv1\n",
      "reinitializing layer block3_conv1.kernel\n",
      "reinitializing layer block3_conv1.bias\n",
      "LAYER:: block3_conv2\n",
      "reinitializing layer block3_conv2.kernel\n",
      "reinitializing layer block3_conv2.bias\n",
      "LAYER:: block3_conv3\n",
      "reinitializing layer block3_conv3.kernel\n",
      "reinitializing layer block3_conv3.bias\n",
      "LAYER:: max_pooling2d_2\n",
      "LAYER:: block4_conv1\n",
      "reinitializing layer block4_conv1.kernel\n",
      "reinitializing layer block4_conv1.bias\n",
      "LAYER:: block4_conv2\n",
      "reinitializing layer block4_conv2.kernel\n",
      "reinitializing layer block4_conv2.bias\n",
      "LAYER:: block4_conv3\n",
      "reinitializing layer block4_conv3.kernel\n",
      "reinitializing layer block4_conv3.bias\n",
      "LAYER:: max_pooling2d_3\n",
      "LAYER:: block5_conv1\n",
      "reinitializing layer block5_conv1.kernel\n",
      "reinitializing layer block5_conv1.bias\n",
      "LAYER:: block5_conv2\n",
      "reinitializing layer block5_conv2.kernel\n",
      "reinitializing layer block5_conv2.bias\n",
      "LAYER:: block5_conv3\n",
      "reinitializing layer block5_conv3.kernel\n",
      "reinitializing layer block5_conv3.bias\n",
      "LAYER:: max_pooling2d_4\n",
      "LAYER:: up_sampling2d\n",
      "LAYER:: conv2d_1\n",
      "LAYER:: batch_normalization\n",
      "LAYER:: conv2d_2\n",
      "LAYER:: batch_normalization_1\n",
      "LAYER:: concatenate\n",
      "LAYER:: up_sampling2d_1\n",
      "LAYER:: conv2d_3\n",
      "LAYER:: conv2d_4\n",
      "LAYER:: concatenate_1\n",
      "LAYER:: up_sampling2d_2\n",
      "LAYER:: conv2d_5\n",
      "LAYER:: conv2d_6\n",
      "LAYER:: concatenate_2\n",
      "LAYER:: up_sampling2d_3\n",
      "LAYER:: conv2d_7\n",
      "LAYER:: conv2d_8\n",
      "LAYER:: concatenate_3\n",
      "LAYER:: up_sampling2d_4\n",
      "LAYER:: conv2d_9\n",
      "LAYER:: conv2d_10\n",
      "LAYER:: concatenate_4\n",
      "LAYER:: conv2d_11\n",
      "LAYER:: re_lu\n",
      "LAYER:: conv2d_12\n",
      "LAYER:: activation\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 1.0234 - acc: 0.7710 - val_loss: 0.8542 - val_acc: 0.7966\n"
     ]
    }
   ],
   "source": [
    "test_title = '50steps'\n",
    "\n",
    "training_params = dict(\n",
    "    train_steps=50, \n",
    "    val_steps=200, \n",
    "    epochs=1, \n",
    "    iterations=30, \n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "for model in models:\n",
    "    print(f'\\nTESTING MODEL: {model[0]}')\n",
    "    results = test_model(model[1], train_loader, test_loader, **training_params, model_params=model[2])\n",
    "    results_df = hists2df(results)\n",
    "    results_df.to_csv(f'{results_pth}{model[0]}_{test_title}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium Test: 1000 training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_title = '1000steps'\n",
    "\n",
    "training_params = dict(\n",
    "    train_steps=1000, \n",
    "    val_steps=200, \n",
    "    epochs=1, \n",
    "    iterations=10, \n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "for model in models:\n",
    "    print(f'\\nTESTING MODEL: {model[0]}')\n",
    "    results = test_model(model[1], train_loader, test_loader, **training_params, model_params=model[2])\n",
    "    results_df = hists2df(results)\n",
    "    results_df.to_csv(f'{results_pth}{model[0]}_{test_title}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old fast test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hists_baseline = fast_test(unet, 30, 50, epochs=1, lr=1e-4)\n",
    "df_baseline = hists2df(hists_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 5))\n",
    "\n",
    "mean, upper, lower = stats(df_zhixuhao)\n",
    "ax1.set_title('zhixuhao model')\n",
    "ax1.plot(list(df_zhixuhao.index), list(df_zhixuhao['acc']))\n",
    "ax1.axhline(y=mean, color='r')\n",
    "ax1.axhline(y=upper, linestyle='--', color='g')\n",
    "ax1.axhline(y=lower, linestyle='--', color='g')\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('accuracy')\n",
    "\n",
    "mean, upper, lower = stats(df_baseline)\n",
    "ax2.set_title('baseline model')\n",
    "ax2.plot(list(df_baseline.index), list(df_zhixuhao['acc']))\n",
    "ax2.axhline(y=mean, color='r')\n",
    "ax2.axhline(y=upper, linestyle='--', color='g')\n",
    "ax2.axhline(y=lower, linestyle='--', color='g')\n",
    "ax2.set_xlabel('iteration');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hists_ternaus = fast_test(ternausNet16, 30, 50, epochs=1, lr=1e-4)\n",
    "df_ternaus = hists2df(hists_ternaus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(df, ):\n",
    "    mean = df['acc'].mean()\n",
    "    upper = mean + df['acc'].std()\n",
    "    lower = mean - df['acc'].std()\n",
    "    return mean, upper, lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 5))\n",
    "\n",
    "mean, upper, lower = stats(df_ternaus)\n",
    "ax1.set_title('ternaus model')\n",
    "ax1.plot(list(df_ternaus.index), list(df_ternaus['acc']))\n",
    "ax1.axhline(y=mean, color='r')\n",
    "ax1.axhline(y=upper, linestyle='--', color='g')\n",
    "ax1.axhline(y=lower, linestyle='--', color='g')\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation tuning\n",
    "\n",
    "## data_loader_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_test(model_fn, iterations, steps_per_iter, epochs=1, lr=1e-4):\n",
    "    hists = []\n",
    "    for i in range(iterations):\n",
    "        model = model_fn(input_size=(256, 256, 1))\n",
    "        model.compile(optimizer = Adam(lr=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit_generator(train_gen, steps_per_epoch=steps_per_iter, epochs=1)\n",
    "        hists.append(history.history)\n",
    "#         r = {k: r[k][-1] for k in r}\n",
    "#         df = df.append(r, ignore_index=True)\n",
    "        backend.clear_session()\n",
    "    return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement test set loader\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                     width_shift_range=0.05,\n",
    "                     height_shift_range=0.05,\n",
    "                     shear_range=0.05,\n",
    "                     zoom_range=0.05,\n",
    "                     horizontal_flip=True,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "# why is batch size 2? paper says bs=1\n",
    "train_gen = trainGenerator(2, train_pth, 'input', 'target', data_gen_args, save_to_dir=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.5742 - acc: 0.8896\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 0.5651 - acc: 0.8921\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 0.4570 - acc: 0.8995\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2041a87435a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhists_baseline_slow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-273635125a8f>\u001b[0m in \u001b[0;36mfast_test\u001b[0;34m(model_fn, iterations, steps_per_iter, epochs, lr)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mhists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#         r = {k: r[k][-1] for k in r}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 176\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2945\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2947\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2948\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2949\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    467\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    736\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hists_baseline_slow = fast_test(unet, 5, 1000, epochs=1, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sz = (256, 256, 1)\n",
    "batch_sz = 2\n",
    "\n",
    "# Models\n",
    "models = [\n",
    "    ['unet_baseline', unet, dict(input_size=img_sz)],\n",
    "]\n",
    "\n",
    "# Data loaders\n",
    "train_loader = loader(train_pth, input_generator_train, target_generator_train, batch_sz=batch_sz, img_sz=img_sz[:2])\n",
    "test_loader = loader(test_pth, input_generator_test, target_generator_test, batch_sz=batch_sz, img_sz=img_sz[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING MODEL: unet_baseline\n",
      "Epoch 1/1\n",
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4675 - acc: 0.8973Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "1000/1000 [==============================] - 166s 166ms/step - loss: 0.4675 - acc: 0.8973 - val_loss: 0.3348 - val_acc: 0.9324\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.4851 - acc: 0.8936 - val_loss: 0.3304 - val_acc: 0.9326\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 1.2724 - acc: 0.8682 - val_loss: 1.1669 - val_acc: 0.9347\n"
     ]
    }
   ],
   "source": [
    "training_params = dict(\n",
    "    train_steps=1000, \n",
    "    val_steps=200, \n",
    "    epochs=1, \n",
    "    iterations=3, \n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "for model in models:\n",
    "    print(f'\\nTESTING MODEL: {model[0]}')\n",
    "    results = test_model(model[1], train_loader, test_loader, **training_params, model_params=model[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test A\n",
    "\n",
    "input_generator_train = ImageDataGenerator(\n",
    "     rotation_range=180,\n",
    "     width_shift_range=0.2,\n",
    "     height_shift_range=0.2,\n",
    "     brightness_range=[0.5, 1.5],\n",
    "     rescale=1./255,           #  rescale pixel vals 0-255 --> 0.0-1.0\n",
    "     shear_range=0.2,\n",
    "     zoom_range=[0.5, 1.0],\n",
    "     horizontal_flip=True,\n",
    "     fill_mode='reflect',\n",
    "     data_format='channels_last',\n",
    "     validation_split=0.0\n",
    " )\n",
    "\n",
    "loss: 0.5713 - acc: 0.8766 - val_loss: 0.3788 - val_acc: 0.9237\n",
    "loss: 0.6409 - acc: 0.8713 - val_loss: 0.4842 - val_acc: 0.9206\n",
    "loss: 1.2721 - acc: 0.8673 - val_loss: 1.1907 - val_acc: 0.9294\n",
    "\n",
    "\n",
    "### Test B\n",
    "\n",
    "input_generator_train = ImageDataGenerator(\n",
    "    rotation_range=0.2,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    #brightness_range=[0.5, 1.5],\n",
    "    rescale=1./255,           #  rescale pixel vals 0-255 --> 0.0-1.0\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest', #nearest\n",
    "    data_format='channels_last',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "loss: 0.4986 - acc: 0.8909 - val_loss: 0.3177 - val_acc: 0.9342\n",
    "loss: 1.3596 - acc: 0.7805 - val_loss: 1.3306 - val_acc: 0.7968\n",
    "loss: 0.4908 - acc: 0.8891 - val_loss: 0.3676 - val_acc: 0.9292\n",
    "\n",
    "\n",
    "### Test C\n",
    "\n",
    "as B:\n",
    "fill_mode='reflect'\n",
    "\n",
    "loss: 0.5527 - acc: 0.8786 - val_loss: 0.3485 - val_acc: 0.9337\n",
    "loss: 0.5636 - acc: 0.8933 - val_loss: 0.4527 - val_acc: 0.9340\n",
    "loss: 0.4779 - acc: 0.8942 - val_loss: 0.3359 - val_acc: 0.9326\n",
    "\n",
    "\n",
    "### Test D\n",
    "\n",
    "as C:\n",
    "rotation_range=0.0,\n",
    "\n",
    "loss: 0.5775 - acc: 0.8873 - val_loss: 0.4613 - val_acc: 0.9319\n",
    "loss: 1.2456 - acc: 0.8952 - val_loss: 1.1706 - val_acc: 0.9309\n",
    "loss: 0.4818 - acc: 0.8946 - val_loss: 0.3495 - val_acc: 0.9314\n",
    "\n",
    "### Test E\n",
    "\n",
    "as C\n",
    "brightness_range=[0.8, 1.2]\n",
    "\n",
    "loss: 0.4811 - acc: 0.8946 - val_loss: 0.3346 - val_acc: 0.9327\n",
    "loss: 0.4701 - acc: 0.8968 - val_loss: 0.4053 - val_acc: 0.9273\n",
    "loss: 0.4712 - acc: 0.8971 - val_loss: 0.3999 - val_acc: 0.9275\n",
    "\n",
    "### Test F\n",
    "\n",
    "as C\n",
    "rotation_range=2,\n",
    "brightness_range=[0.8, 1.2]\n",
    "\n",
    "loss: 0.4675 - acc: 0.8973 - val_loss: 0.3348 - val_acc: 0.9324\n",
    "loss: 0.4851 - acc: 0.8936 - val_loss: 0.3304 - val_acc: 0.9326\n",
    "loss: 1.2724 - acc: 0.8682 - val_loss: 1.1669 - val_acc: 0.9347"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slow test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 187s 187ms/step - loss: 1.3618 - acc: 0.7804\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.5108 - acc: 0.8934\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.5411 - acc: 0.8715\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.7130 - acc: 0.8497\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.4790 - acc: 0.8942\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 190s 190ms/step - loss: 0.5763 - acc: 0.8883\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.5646 - acc: 0.8913\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.5737 - acc: 0.8881\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.5536 - acc: 0.8961\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.5516 - acc: 0.8968\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.5497 - acc: 0.8820\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.5618 - acc: 0.8927\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.5209 - acc: 0.8787\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 190s 190ms/step - loss: 0.5802 - acc: 0.8867\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 190s 190ms/step - loss: 0.5811 - acc: 0.8872\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.5046 - acc: 0.8866\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 189s 189ms/step - loss: 0.5635 - acc: 0.8915\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 190s 190ms/step - loss: 0.4630 - acc: 0.8967\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 190s 190ms/step - loss: 0.4753 - acc: 0.8957\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 190s 190ms/step - loss: 0.5582 - acc: 0.8943\n"
     ]
    }
   ],
   "source": [
    "hists_zhixuhao_slow = fast_test(unet_zhixuhao, 10, 1000, epochs=1, lr=1e-4)\n",
    "hists_baseline_slow = fast_test(unet, 10, 1000, epochs=1, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zhixuhao_slow = hists2df(hists_zhixuhao_slow)\n",
    "df_baseline_slow = hists2df(hists_baseline_slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def stats(df):\n",
    "    mean = df['acc'].mean()\n",
    "    upper = mean + df['acc'].std()\n",
    "    lower = mean - df['acc'].std()\n",
    "    return mean, upper, lower\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 5))\n",
    "\n",
    "mean, upper, lower = stats(df_zhixuhao_slow)\n",
    "ax1.set_title('zhixuhao model')\n",
    "ax1.plot(list(df_zhixuhao_slow.index), list(df_zhixuhao_slow['acc']))\n",
    "ax1.axhline(y=mean, color='r')\n",
    "ax1.axhline(y=upper, linestyle='--', color='g')\n",
    "ax1.axhline(y=lower, linestyle='--', color='g')\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('accuracy')\n",
    "\n",
    "mean, upper, lower = stats(df_baseline_slow)\n",
    "ax2.set_title('baseline model')\n",
    "ax2.plot(list(df_baseline_slow.index), list(df_baseline_slow['acc']))\n",
    "ax2.axhline(y=mean, color='r')\n",
    "ax2.axhline(y=upper, linestyle='--', color='g')\n",
    "ax2.axhline(y=lower, linestyle='--', color='g')\n",
    "ax2.set_xlabel('iteration');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ternausNet16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-91e6cd586b98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhists_ternaus_slow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mternausNet16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ternausNet16' is not defined"
     ]
    }
   ],
   "source": [
    "hists_ternaus_slow = fast_test(ternausNet16, 10, 1000, epochs=1, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ternaus Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ternausNet16(input_size=(256, 256, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "2000/2000 [==============================] - 409s 205ms/step - loss: 0.3079 - acc: 0.9330\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 404s 202ms/step - loss: 0.1859 - acc: 0.9594\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 404s 202ms/step - loss: 0.1514 - acc: 0.9670\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 403s 202ms/step - loss: 0.1338 - acc: 0.9708\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 403s 201ms/step - loss: 0.1219 - acc: 0.9734\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, steps_per_epoch=2000, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std(df, column:str):\n",
    "    \"\"\"Get mean and upper/lower bounds of variance\"\"\"\n",
    "    mean = df[column].mean()\n",
    "    upper = mean + df[column].std()\n",
    "    lower = mean - df[column].std()\n",
    "    return mean, upper, lower\n",
    "\n",
    "rows = 1\n",
    "cols = 8\n",
    "f, axes = plt.subplots(rows, cols, sharey=True, figsize=(15, 5))\n",
    "\n",
    "for i in range(cols):\n",
    "    title = f'{models[i][0]}'\n",
    "    df = pd.read_csv(f'{results_pth}{title}_30steps.csv')\n",
    "    mean, upper, lower = mean_std(df, 'val_acc')\n",
    "    axes[i].set_title(title[5:])\n",
    "    axes[i].plot(list(df.index), list(df['val_acc']))\n",
    "    axes[i].axhline(y=mean, color='r')\n",
    "    axes[i].axhline(y=upper, linestyle='--', color='g')\n",
    "    axes[i].axhline(y=lower, linestyle='--', color='g')\n",
    "    axes[i].set_xlabel('iteration')\n",
    "    if i ==0:\n",
    "        axes[i].set_ylabel('accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ternaus_2000_5_df = pd.DataFrame(history.history)\n",
    "ternaus_file = f'{results_pth}ternaus_2000_5.csv'\n",
    "ternaus_2000_5_df.to_csv(ternaus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(ternaus_file)\n",
    "x = df.index\n",
    "plt.plot(x, df['acc']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
