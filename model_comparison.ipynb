{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from utils import *\n",
    "from model.data_loader import *\n",
    "from model.unet_baseline import unet\n",
    "from model.unet_ternaus import ternausNet16\n",
    "from model.unet_ternaus_tweaked import ternausNet16_tweaked\n",
    "from model.unet_pix2pix import unet_pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pth = 'data/membrane/train'\n",
    "test_pth = 'data/membrane/test'\n",
    "results_pth = 'results/'\n",
    "pretrained_pth = 'pretrained/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "Train the original unet model on the full 512px dataset until overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sz = (512, 512, 1)\n",
    "batch_sz = 2\n",
    "\n",
    "# Models\n",
    "models = [\n",
    "    ['unet_baseline', unet, dict(input_size=img_sz, transpose=True)]\n",
    "]\n",
    "\n",
    "# Data loaders\n",
    "train_loader = loader(train_pth, input_generator_train, target_generator_train, \n",
    "                      batch_sz=batch_sz, img_sz=img_sz[:2])\n",
    "test_loader = loader(test_pth, input_generator_test, target_generator_test, \n",
    "                     batch_sz=batch_sz, img_sz=img_sz[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING MODEL: unet_baseline\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 259s 519ms/step - loss: 0.5889 - acc: 0.8872 - val_loss: 0.4561 - val_acc: 0.9299\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 257s 515ms/step - loss: 0.4870 - acc: 0.9201 - val_loss: 0.4700 - val_acc: 0.9347\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 257s 514ms/step - loss: 0.4551 - acc: 0.9270 - val_loss: 0.4470 - val_acc: 0.9349\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 257s 514ms/step - loss: 0.4327 - acc: 0.9318 - val_loss: 0.4386 - val_acc: 0.9376\n",
      "Epoch 5/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.4139 - acc: 0.9358\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "500/500 [==============================] - 255s 511ms/step - loss: 0.4139 - acc: 0.9358 - val_loss: 0.4374 - val_acc: 0.9367\n",
      "Epoch 6/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.4003 - acc: 0.9396\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "500/500 [==============================] - 255s 511ms/step - loss: 0.4003 - acc: 0.9396 - val_loss: 0.4717 - val_acc: 0.9371\n"
     ]
    }
   ],
   "source": [
    "test_title = '512px_500steps_10epochs'\n",
    "\n",
    "training_params = dict(\n",
    "    train_steps=500, \n",
    "    val_steps=100, \n",
    "    epochs=10, \n",
    "    iterations=1, \n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "for model in models:\n",
    "    print(f'\\nTESTING MODEL: {model[0]}')\n",
    "    save_pth = f'{pretrained_pth}{model[0]}_{test_title}.h5'\n",
    "    results = test_model(model[1], train_loader, test_loader, **training_params, \n",
    "                         model_params=model[2], save_pth=save_pth)\n",
    "    results_df = hists2df(results)\n",
    "    results_df.to_csv(f'{results_pth}{model[0]}_{test_title}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Validation Accuracy: 0.9376"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Test: 20 epochs of 250 training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sz = (256, 256, 1)\n",
    "batch_sz = 2\n",
    "\n",
    "# Models\n",
    "models = [\n",
    "#     ['unet_baseline',           unet,                 dict(input_size=img_sz, transpose=True)],\n",
    "#     ['unet_baseline_upsampled', unet,                 dict(input_size=img_sz, transpose=False)],\n",
    "#     ['unet_ternaus_nopre',      ternausNet16_tweaked, dict(input_size=img_sz, dropout=False, batch_norm=False, pretrained=False)],\n",
    "#     ['unet_ternaus',            ternausNet16,         dict(input_size=img_sz)],\n",
    "#     ['unet_ternaus_drop',       ternausNet16_tweaked, dict(input_size=img_sz, dropout=True,  batch_norm=False, pretrained=True)],\n",
    "#     ['unet_ternaus_bn',         ternausNet16_tweaked, dict(input_size=img_sz, dropout=False, batch_norm=True,  pretrained=True)],\n",
    "#     ['unet_ternaus_dropbn',     ternausNet16_tweaked, dict(input_size=img_sz, dropout=True,  batch_norm=True,  pretrained=True)],\n",
    "    ['unet_pix2pix',            unet_pix2pix, dict(input_size=img_sz)]\n",
    "]\n",
    "\n",
    "# Data loaders\n",
    "train_loader = loader(train_pth, input_generator_train, target_generator_train, batch_sz=batch_sz, img_sz=img_sz[:2])\n",
    "test_loader = loader(test_pth, input_generator_test, target_generator_test, batch_sz=batch_sz, img_sz=img_sz[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING MODEL: unet_pix2pix\n",
      "WARNING:tensorflow:From /home/paperspace/git/pix2pix/venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/paperspace/git/pix2pix/venv/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/paperspace/git/pix2pix/venv/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "Epoch 1/20\n",
      "249/250 [============================>.] - ETA: 0s - loss: 4.1364 - acc: 0.2600Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 2.6649 - acc: 0.3605\n",
      "250/250 [==============================] - 42s 169ms/step - loss: 4.1305 - acc: 0.2605 - val_loss: 2.6649 - val_acc: 0.3605\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 1.1007 - acc: 0.7706\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 1.3803 - acc: 0.6194 - val_loss: 1.1007 - val_acc: 0.7706\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.8961 - acc: 0.8289\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.9906 - acc: 0.7967 - val_loss: 0.8961 - val_acc: 0.8289\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7728 - acc: 0.8507\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.8399 - acc: 0.8233 - val_loss: 0.7728 - val_acc: 0.8507\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7034 - acc: 0.8606\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.7521 - acc: 0.8369 - val_loss: 0.7034 - val_acc: 0.8606\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6637 - acc: 0.8684\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.6990 - acc: 0.8459 - val_loss: 0.6637 - val_acc: 0.8684\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6354 - acc: 0.8729\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.6651 - acc: 0.8529 - val_loss: 0.6354 - val_acc: 0.8729\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5968 - acc: 0.8797\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.6406 - acc: 0.8588 - val_loss: 0.5968 - val_acc: 0.8797\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6180 - acc: 0.8783\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "250/250 [==============================] - 34s 137ms/step - loss: 0.6206 - acc: 0.8640 - val_loss: 0.6180 - val_acc: 0.8783\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5891 - acc: 0.8827\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.6126 - acc: 0.8663 - val_loss: 0.5891 - val_acc: 0.8827\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5931 - acc: 0.8816\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "250/250 [==============================] - 34s 137ms/step - loss: 0.6109 - acc: 0.8667 - val_loss: 0.5931 - val_acc: 0.8816\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5928 - acc: 0.8825\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "250/250 [==============================] - 34s 136ms/step - loss: 0.6090 - acc: 0.8673 - val_loss: 0.5928 - val_acc: 0.8825\n",
      "Epoch 00012: early stopping\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.4754 - acc: 0.4623\n",
      "250/250 [==============================] - 41s 164ms/step - loss: 2.5571 - acc: 0.2938 - val_loss: 1.4754 - val_acc: 0.4623\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.0848 - acc: 0.7643\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 1.2515 - acc: 0.6421 - val_loss: 1.0848 - val_acc: 0.7643\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8868 - acc: 0.8292\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.9695 - acc: 0.7952 - val_loss: 0.8868 - val_acc: 0.8292\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7763 - acc: 0.8532\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.8256 - acc: 0.8231 - val_loss: 0.7763 - val_acc: 0.8532\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6865 - acc: 0.8635\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.7410 - acc: 0.8381 - val_loss: 0.6865 - val_acc: 0.8635\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6613 - acc: 0.8729\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.6885 - acc: 0.8484 - val_loss: 0.6613 - val_acc: 0.8729\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6542 - acc: 0.8714\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "250/250 [==============================] - 34s 137ms/step - loss: 0.6543 - acc: 0.8560 - val_loss: 0.6542 - val_acc: 0.8714\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6150 - acc: 0.8792\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.6385 - acc: 0.8601 - val_loss: 0.6150 - val_acc: 0.8792\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6166 - acc: 0.8794\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.6354 - acc: 0.8604 - val_loss: 0.6166 - val_acc: 0.8794\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6076 - acc: 0.8790\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "250/250 [==============================] - 33s 134ms/step - loss: 0.6331 - acc: 0.8614 - val_loss: 0.6076 - val_acc: 0.8790\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6139 - acc: 0.8783\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "250/250 [==============================] - 33s 133ms/step - loss: 0.6298 - acc: 0.8623 - val_loss: 0.6139 - val_acc: 0.8783\n",
      "Epoch 00011: early stopping\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.5443 - acc: 0.3942\n",
      "250/250 [==============================] - 40s 159ms/step - loss: 2.9194 - acc: 0.2672 - val_loss: 1.5443 - val_acc: 0.3942\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 1.1422 - acc: 0.7511\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 1.3096 - acc: 0.6064 - val_loss: 1.1422 - val_acc: 0.7511\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.9277 - acc: 0.8134\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 1.0264 - acc: 0.7836 - val_loss: 0.9277 - val_acc: 0.8134\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.8026 - acc: 0.8292\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.8820 - acc: 0.8060 - val_loss: 0.8026 - val_acc: 0.8292\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7345 - acc: 0.8437\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.7955 - acc: 0.8198 - val_loss: 0.7345 - val_acc: 0.8437\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.6997 - acc: 0.8571\n",
      "250/250 [==============================] - 36s 142ms/step - loss: 0.7382 - acc: 0.8311 - val_loss: 0.6997 - val_acc: 0.8571\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6606 - acc: 0.8650\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.6990 - acc: 0.8403 - val_loss: 0.6606 - val_acc: 0.8650\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6585 - acc: 0.8715\n",
      "250/250 [==============================] - 35s 141ms/step - loss: 0.6680 - acc: 0.8491 - val_loss: 0.6585 - val_acc: 0.8715\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6218 - acc: 0.8758\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.6465 - acc: 0.8557 - val_loss: 0.6218 - val_acc: 0.8758\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.6285 - acc: 0.8750\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.6278 - acc: 0.8612 - val_loss: 0.6285 - val_acc: 0.8750\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6075 - acc: 0.8802\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.6150 - acc: 0.8651 - val_loss: 0.6075 - val_acc: 0.8802\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6071 - acc: 0.8817\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.6136 - acc: 0.8656 - val_loss: 0.6071 - val_acc: 0.8817\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5938 - acc: 0.8816\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.6125 - acc: 0.8659 - val_loss: 0.5938 - val_acc: 0.8816\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.6045 - acc: 0.8810\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.6155 - acc: 0.8649 - val_loss: 0.6045 - val_acc: 0.8810\n",
      "Epoch 00014: early stopping\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 1.5264 - acc: 0.4263\n",
      "250/250 [==============================] - 40s 159ms/step - loss: 2.6101 - acc: 0.2864 - val_loss: 1.5264 - val_acc: 0.4263\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.1546 - acc: 0.7260\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 1.3031 - acc: 0.6027 - val_loss: 1.1546 - val_acc: 0.7260\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.9399 - acc: 0.8140\n",
      "250/250 [==============================] - 35s 141ms/step - loss: 1.0292 - acc: 0.7765 - val_loss: 0.9399 - val_acc: 0.8140\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.8089 - acc: 0.8337\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.8849 - acc: 0.8085 - val_loss: 0.8089 - val_acc: 0.8337\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.7490 - acc: 0.8527\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.7956 - acc: 0.8237 - val_loss: 0.7490 - val_acc: 0.8527\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.7087 - acc: 0.8631\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.7365 - acc: 0.8354 - val_loss: 0.7087 - val_acc: 0.8631\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.6867 - acc: 0.8644\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.6951 - acc: 0.8447 - val_loss: 0.6867 - val_acc: 0.8644\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.6188 - acc: 0.8757\n",
      "250/250 [==============================] - 35s 142ms/step - loss: 0.6619 - acc: 0.8533 - val_loss: 0.6188 - val_acc: 0.8757\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.6823 - acc: 0.8662\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "250/250 [==============================] - 33s 133ms/step - loss: 0.6395 - acc: 0.8593 - val_loss: 0.6823 - val_acc: 0.8662\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.6005 - acc: 0.8791\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.6263 - acc: 0.8629 - val_loss: 0.6005 - val_acc: 0.8791\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.5856 - acc: 0.8828\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.6232 - acc: 0.8637 - val_loss: 0.5856 - val_acc: 0.8828\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.5886 - acc: 0.8827\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "250/250 [==============================] - 34s 134ms/step - loss: 0.6210 - acc: 0.8643 - val_loss: 0.5886 - val_acc: 0.8827\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.5947 - acc: 0.8820\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "250/250 [==============================] - 33s 134ms/step - loss: 0.6221 - acc: 0.8644 - val_loss: 0.5947 - val_acc: 0.8820\n",
      "Epoch 00013: early stopping\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 1.8099 - acc: 0.2748\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 3.9861 - acc: 0.2326 - val_loss: 1.8099 - val_acc: 0.2748\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 1.3179 - acc: 0.6005\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 1.5143 - acc: 0.4369 - val_loss: 1.3179 - val_acc: 0.6005\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 1.0585 - acc: 0.7892\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 1.1667 - acc: 0.7210 - val_loss: 1.0585 - val_acc: 0.7892\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.9189 - acc: 0.8207\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.9829 - acc: 0.7928 - val_loss: 0.9189 - val_acc: 0.8207\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.8065 - acc: 0.8345\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.8712 - acc: 0.8091 - val_loss: 0.8065 - val_acc: 0.8345\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.7522 - acc: 0.8520\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.7934 - acc: 0.8233 - val_loss: 0.7522 - val_acc: 0.8520\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.7050 - acc: 0.8625\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.7359 - acc: 0.8353 - val_loss: 0.7050 - val_acc: 0.8625\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6762 - acc: 0.8685\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.6925 - acc: 0.8454 - val_loss: 0.6762 - val_acc: 0.8685\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6236 - acc: 0.8753\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.6603 - acc: 0.8534 - val_loss: 0.6236 - val_acc: 0.8753\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.6012 - acc: 0.8811\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.6325 - acc: 0.8610 - val_loss: 0.6012 - val_acc: 0.8811\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.5703 - acc: 0.8860\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.6120 - acc: 0.8668 - val_loss: 0.5703 - val_acc: 0.8860\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.5718 - acc: 0.8876\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.5903 - acc: 0.8730 - val_loss: 0.5718 - val_acc: 0.8876\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.5561 - acc: 0.8906\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.5676 - acc: 0.8791 - val_loss: 0.5561 - val_acc: 0.8906\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.5665 - acc: 0.8848: 1s - loss\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "250/250 [==============================] - 34s 135ms/step - loss: 0.5474 - acc: 0.8839 - val_loss: 0.5665 - val_acc: 0.8848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.5203 - acc: 0.8974\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.5343 - acc: 0.8873 - val_loss: 0.5203 - val_acc: 0.8974\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.4996 - acc: 0.8992\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.5334 - acc: 0.8873 - val_loss: 0.4996 - val_acc: 0.8992\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.5021 - acc: 0.9007\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.5315 - acc: 0.8876 - val_loss: 0.5021 - val_acc: 0.9007\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.5153 - acc: 0.8982\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "250/250 [==============================] - 33s 134ms/step - loss: 0.5297 - acc: 0.8879 - val_loss: 0.5153 - val_acc: 0.8982\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4975 - acc: 0.9005\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "250/250 [==============================] - 33s 134ms/step - loss: 0.5283 - acc: 0.8882 - val_loss: 0.4975 - val_acc: 0.9005\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "test_title = '256px_250steps_20epochs'\n",
    "\n",
    "training_params = dict(\n",
    "    train_steps=250, \n",
    "    val_steps=100, \n",
    "    epochs=20, \n",
    "    iterations=5, \n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "for model in models:\n",
    "    print(f'\\nTESTING MODEL: {model[0]}')\n",
    "    save_pth = f'{pretrained_pth}{model[0]}_{test_title}.h5'\n",
    "    results = test_model(model[1], train_loader, test_loader, **training_params, \n",
    "                         model_params=model[2], save_pth=save_pth)\n",
    "    results_df = hists2df(results)\n",
    "    results_df.to_csv(f'{results_pth}{model[0]}_{test_title}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING MODEL: unet_baseline \n",
    "train_steps=1000\n",
    "epochs=5\n",
    "\n",
    "new augmentation\n",
    "\n",
    "loss: 0.4721 - acc: 0.8949 - val_loss: 0.3291 - val_acc: 0.9325\n",
    "loss: 0.3288 - acc: 0.9284 - val_loss: 0.3316 - val_acc: 0.9346\n",
    "loss: 0.2828 - acc: 0.9381 - val_loss: 0.3206 - val_acc: 0.9349\n",
    "loss: 0.2543 - acc: 0.9443 - val_loss: 0.3570 - val_acc: 0.9299  <--overfitting\n",
    "loss: 0.2304 - acc: 0.9496 - val_loss: 0.3599 - val_acc: 0.9341\n",
    "\n",
    "512px 2000 steps\n",
    "loss: 1.1966 - acc: 0.9010 - val_loss: 1.0991 - val_acc: 0.9367\n",
    "loss: 1.0032 - acc: 0.9439 - val_loss: 1.0317 - val_acc: 0.9312  <--overfitting\n",
    "\n",
    "old augmentation\n",
    "\n",
    ",val_loss,val_acc,loss,acc,experiment,epoch\n",
    "0,0.3938294525444508,0.9204465866088867,0.5577377219498157,0.8792923736572266,0.0,0.0\n",
    "1,0.3559911660850048,0.9349861907958984,0.4401548975408077,0.9053520278930665,0.0,1.0\n",
    "2,0.39109488159418104,0.9267212295532227,0.4238285449743271,0.9082808227539062,0.0,2.0    <--overfitting\n",
    "3,0.4155013260245323,0.9168938446044922,0.42954228895902635,0.9082791290283203,0.0,3.0\n",
    "4,0.36537827536463735,0.9267246627807617,0.39881821677088736,0.9130117721557617,0.0,4.0\n",
    "\n",
    "5,0.49226998195052146,0.9182594680786133,0.6562534253895282,0.8670453491210938,1.0,0.0\n",
    "6,0.4583278933167458,0.9273256683349609,0.554767794162035,0.8987517471313476,1.0,1.0\n",
    "7,0.4612529504299164,0.9287994384765625,0.5254129691720009,0.904376106262207,1.0,2.0\n",
    "8,0.4672836236655712,0.9274766540527344,0.5032809109687805,0.9079330139160157,1.0,3.0   <--overfitting\n",
    "9,0.4568671178817749,0.922571907043457,0.5079058838784695,0.9074051818847656,1.0,4.0\n",
    "\n",
    "10,1.3314954286813736,0.7966962432861329,1.3639041519165038,0.7678601226806641,2.0,0.0\n",
    "11,1.282408196926117,0.7967258834838867,1.3139923479557036,0.7705478591918945,2.0,1.0\n",
    "12,1.2392406225204469,0.7965563201904297,1.273618043422699,0.7686567840576172,2.0,2.0\n",
    "13,1.2005380243062973,0.7966357803344727,1.237180896639824,0.769509765625,2.0,3.0\n",
    "14,1.166281766295433,0.7965296936035157,1.2050516810417176,0.7705629653930665,2.0,4.0\n",
    "\n",
    "15,0.47512905225157737,0.9222694778442383,0.6407421391904354,0.8729847259521485,3.0,0.0\n",
    "16,0.4551257087290287,0.9326386260986328,0.5516852941811085,0.8992034530639649,3.0,1.0\n",
    "17,0.47955494463443754,0.9300589370727539,0.5159895688593388,0.9065925064086914,3.0,2.0 \n",
    "18,0.4419742250442505,0.9331255340576172,0.5083408271372318,0.9076029663085937,3.0,3.0\n",
    "19,0.4340150611102581,0.9320641326904296,0.4795567348897457,0.9116422729492187,3.0,4.0    <--overfitting\n",
    "\n",
    "20,0.37043760359287264,0.9277394485473632,0.5708116674721241,0.8749972534179687,4.0,0.0\n",
    "21,0.3530151304602623,0.9324607086181641,0.4412955792546272,0.9052258071899414,4.0,1.0\n",
    "22,0.3365512517094612,0.935040283203125,0.43223093220591546,0.9074309005737304,4.0,2.0\n",
    "23,0.3444555760920048,0.930106315612793,0.4199221305847168,0.9092439498901367,4.0,3.0   <--overfitting\n",
    "24,0.34377639517188074,0.9305371475219727,0.40034309843182564,0.9129037475585937,4.0,4.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TESTING MODEL: unet_ternaus\n",
    "train_steps=2000\n",
    "epochs=5\n",
    "\n",
    "loss: 0.3033 - acc: 0.9342 - val_loss: 0.3997 - val_acc: 0.9302\n",
    "loss: 0.1896 - acc: 0.9586 - val_loss: 0.4191 - val_acc: 0.9312\n",
    "loss: 0.1561 - acc: 0.9660 - val_loss: 0.4229 - val_acc: 0.9336\n",
    "loss: 0.1372 - acc: 0.9701 - val_loss: 0.4552 - val_acc: 0.9294  <--overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast test: 50 training steps\n",
    "\n",
    "## Compare baseline implementation to more recent u-net implementations\n",
    "\n",
    "\n",
    "TODO: update\n",
    "\n",
    "It is observed that the final accuracy of both models varies in the range 80-96% when trained for 5 epochs with 2000 iterations. How can we quickly compare the performance of these two models?\n",
    "\n",
    "Here's a quick comparison of models by training each for 50 training steps from scratch 30 times. We compare our baseline implementation to [zhixuhao's model](https://github.com/zhixuhao/unet) and find no significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING MODEL: unet_pix2pix\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 5.8225 - acc: 0.2034\n",
      "50/50 [==============================] - 12s 248ms/step - loss: 10.3476 - acc: 0.2237 - val_loss: 5.8225 - val_acc: 0.2034\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 3.0336 - acc: 0.2031\n",
      "50/50 [==============================] - 12s 248ms/step - loss: 5.8625 - acc: 0.2231 - val_loss: 3.0336 - val_acc: 0.2031\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 4.5115 - acc: 0.2035\n",
      "50/50 [==============================] - 12s 249ms/step - loss: 9.3518 - acc: 0.2201 - val_loss: 4.5115 - val_acc: 0.2035\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 3.4247 - acc: 0.2032\n",
      "50/50 [==============================] - 12s 245ms/step - loss: 5.8055 - acc: 0.2202 - val_loss: 3.4247 - val_acc: 0.2032\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 5.4437 - acc: 0.2034\n",
      "50/50 [==============================] - 12s 248ms/step - loss: 9.4541 - acc: 0.2206 - val_loss: 5.4437 - val_acc: 0.2034\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 5.8741 - acc: 0.2033\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 9.7477 - acc: 0.2206 - val_loss: 5.8741 - val_acc: 0.2033\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 4.1885 - acc: 0.2033\n",
      "50/50 [==============================] - 12s 247ms/step - loss: 9.6231 - acc: 0.2216 - val_loss: 4.1885 - val_acc: 0.2033\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 3.2040 - acc: 0.2031\n",
      "50/50 [==============================] - 12s 249ms/step - loss: 6.6610 - acc: 0.2209 - val_loss: 3.2040 - val_acc: 0.2031\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 3.6220 - acc: 0.2036\n",
      "50/50 [==============================] - 12s 249ms/step - loss: 6.3022 - acc: 0.2194 - val_loss: 3.6220 - val_acc: 0.2036\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 3.7733 - acc: 0.2032\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 7.1181 - acc: 0.2209 - val_loss: 3.7733 - val_acc: 0.2032\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 3.7046 - acc: 0.2030\n",
      "50/50 [==============================] - 12s 248ms/step - loss: 6.7688 - acc: 0.2231 - val_loss: 3.7046 - val_acc: 0.2030\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 5.6521 - acc: 0.2031\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 9.9922 - acc: 0.2187 - val_loss: 5.6521 - val_acc: 0.2031\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 2.9310 - acc: 0.2032\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 7.8037 - acc: 0.2229 - val_loss: 2.9310 - val_acc: 0.2032\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 3.2042 - acc: 0.2036\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 6.3761 - acc: 0.2219 - val_loss: 3.2042 - val_acc: 0.2036\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 3.2645 - acc: 0.2030\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 7.9495 - acc: 0.2212 - val_loss: 3.2645 - val_acc: 0.2030\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 2.7769 - acc: 0.2033\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 6.2316 - acc: 0.2219 - val_loss: 2.7769 - val_acc: 0.2033\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 2.8458 - acc: 0.2034\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 4.4399 - acc: 0.2209 - val_loss: 2.8458 - val_acc: 0.2034\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 3.2228 - acc: 0.2025\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 5.2652 - acc: 0.2226 - val_loss: 3.2228 - val_acc: 0.2025\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 6.0160 - acc: 0.2035\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 8.5689 - acc: 0.2202 - val_loss: 6.0160 - val_acc: 0.2035\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 5.7268 - acc: 0.2031\n",
      "50/50 [==============================] - 13s 250ms/step - loss: 9.2893 - acc: 0.2209 - val_loss: 5.7268 - val_acc: 0.2031\n"
     ]
    }
   ],
   "source": [
    "test_title = '256px_50steps'\n",
    "\n",
    "training_params = dict(\n",
    "    train_steps=50, \n",
    "    val_steps=100, \n",
    "    epochs=1, \n",
    "    iterations=20, \n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "for model in models:\n",
    "    print(f'\\nTESTING MODEL: {model[0]}')\n",
    "    results = test_model(model[1], train_loader, test_loader, **training_params, \n",
    "                         model_params=model[2])\n",
    "    results_df = hists2df(results)\n",
    "    results_df.to_csv(f'{results_pth}{model[0]}_{test_title}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation tuning\n",
    "\n",
    "## data_loader_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_test(model_fn, iterations, steps_per_iter, epochs=1, lr=1e-4):\n",
    "    hists = []\n",
    "    for i in range(iterations):\n",
    "        model = model_fn(input_size=(256, 256, 1))\n",
    "        model.compile(optimizer = Adam(lr=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit_generator(train_gen, steps_per_epoch=steps_per_iter, epochs=1)\n",
    "        hists.append(history.history)\n",
    "#         r = {k: r[k][-1] for k in r}\n",
    "#         df = df.append(r, ignore_index=True)\n",
    "        backend.clear_session()\n",
    "    return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement test set loader\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                     width_shift_range=0.05,\n",
    "                     height_shift_range=0.05,\n",
    "                     shear_range=0.05,\n",
    "                     zoom_range=0.05,\n",
    "                     horizontal_flip=True,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "# why is batch size 2? paper says bs=1\n",
    "train_gen = trainGenerator(2, train_pth, 'input', 'target', data_gen_args, save_to_dir=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.5742 - acc: 0.8896\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 0.5651 - acc: 0.8921\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 0.4570 - acc: 0.8995\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2041a87435a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhists_baseline_slow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-273635125a8f>\u001b[0m in \u001b[0;36mfast_test\u001b[0;34m(model_fn, iterations, steps_per_iter, epochs, lr)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mhists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#         r = {k: r[k][-1] for k in r}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 176\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2945\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2947\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2948\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2949\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    467\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    736\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hists_baseline_slow = fast_test(unet, 5, 1000, epochs=1, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sz = (256, 256, 1)\n",
    "batch_sz = 2\n",
    "\n",
    "# Models\n",
    "models = [\n",
    "    ['unet_baseline', unet, dict(input_size=img_sz)],\n",
    "]\n",
    "\n",
    "# Data loaders\n",
    "train_loader = loader(train_pth, input_generator_train, target_generator_train, batch_sz=batch_sz, img_sz=img_sz[:2])\n",
    "test_loader = loader(test_pth, input_generator_test, target_generator_test, batch_sz=batch_sz, img_sz=img_sz[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING MODEL: unet_baseline\n",
      "Epoch 1/1\n",
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4675 - acc: 0.8973Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "1000/1000 [==============================] - 166s 166ms/step - loss: 0.4675 - acc: 0.8973 - val_loss: 0.3348 - val_acc: 0.9324\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.4851 - acc: 0.8936 - val_loss: 0.3304 - val_acc: 0.9326\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 1.2724 - acc: 0.8682 - val_loss: 1.1669 - val_acc: 0.9347\n"
     ]
    }
   ],
   "source": [
    "training_params = dict(\n",
    "    train_steps=1000, \n",
    "    val_steps=200, \n",
    "    epochs=1, \n",
    "    iterations=3, \n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "for model in models:\n",
    "    print(f'\\nTESTING MODEL: {model[0]}')\n",
    "    results = test_model(model[1], train_loader, test_loader, **training_params, model_params=model[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test A\n",
    "\n",
    "input_generator_train = ImageDataGenerator(\n",
    "     rotation_range=180,\n",
    "     width_shift_range=0.2,\n",
    "     height_shift_range=0.2,\n",
    "     brightness_range=[0.5, 1.5],\n",
    "     rescale=1./255,           #  rescale pixel vals 0-255 --> 0.0-1.0\n",
    "     shear_range=0.2,\n",
    "     zoom_range=[0.5, 1.0],\n",
    "     horizontal_flip=True,\n",
    "     fill_mode='reflect',\n",
    "     data_format='channels_last',\n",
    "     validation_split=0.0\n",
    " )\n",
    "\n",
    "loss: 0.5713 - acc: 0.8766 - val_loss: 0.3788 - val_acc: 0.9237\n",
    "loss: 0.6409 - acc: 0.8713 - val_loss: 0.4842 - val_acc: 0.9206\n",
    "loss: 1.2721 - acc: 0.8673 - val_loss: 1.1907 - val_acc: 0.9294\n",
    "\n",
    "\n",
    "### Test B\n",
    "\n",
    "input_generator_train = ImageDataGenerator(\n",
    "    rotation_range=0.2,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    #brightness_range=[0.5, 1.5],\n",
    "    rescale=1./255,           #  rescale pixel vals 0-255 --> 0.0-1.0\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest', #nearest\n",
    "    data_format='channels_last',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "loss: 0.4986 - acc: 0.8909 - val_loss: 0.3177 - val_acc: 0.9342\n",
    "loss: 1.3596 - acc: 0.7805 - val_loss: 1.3306 - val_acc: 0.7968\n",
    "loss: 0.4908 - acc: 0.8891 - val_loss: 0.3676 - val_acc: 0.9292\n",
    "\n",
    "\n",
    "### Test C\n",
    "\n",
    "as B:\n",
    "fill_mode='reflect'\n",
    "\n",
    "loss: 0.5527 - acc: 0.8786 - val_loss: 0.3485 - val_acc: 0.9337\n",
    "loss: 0.5636 - acc: 0.8933 - val_loss: 0.4527 - val_acc: 0.9340\n",
    "loss: 0.4779 - acc: 0.8942 - val_loss: 0.3359 - val_acc: 0.9326\n",
    "\n",
    "\n",
    "### Test D\n",
    "\n",
    "as C:\n",
    "rotation_range=0.0,\n",
    "\n",
    "loss: 0.5775 - acc: 0.8873 - val_loss: 0.4613 - val_acc: 0.9319\n",
    "loss: 1.2456 - acc: 0.8952 - val_loss: 1.1706 - val_acc: 0.9309\n",
    "loss: 0.4818 - acc: 0.8946 - val_loss: 0.3495 - val_acc: 0.9314\n",
    "\n",
    "### Test E\n",
    "\n",
    "as C\n",
    "brightness_range=[0.8, 1.2]\n",
    "\n",
    "loss: 0.4811 - acc: 0.8946 - val_loss: 0.3346 - val_acc: 0.9327\n",
    "loss: 0.4701 - acc: 0.8968 - val_loss: 0.4053 - val_acc: 0.9273\n",
    "loss: 0.4712 - acc: 0.8971 - val_loss: 0.3999 - val_acc: 0.9275\n",
    "\n",
    "### Test F\n",
    "\n",
    "as C\n",
    "rotation_range=2,\n",
    "brightness_range=[0.8, 1.2]\n",
    "\n",
    "loss: 0.4675 - acc: 0.8973 - val_loss: 0.3348 - val_acc: 0.9324\n",
    "loss: 0.4851 - acc: 0.8936 - val_loss: 0.3304 - val_acc: 0.9326\n",
    "loss: 1.2724 - acc: 0.8682 - val_loss: 1.1669 - val_acc: 0.9347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
